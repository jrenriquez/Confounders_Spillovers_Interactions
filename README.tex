\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{titling}

\setlength{\droptitle}{-10em}

\title{Confounding, spillovers, and interactions
influence estimates of social distancing policy effects}
\date{\vspace{-10mm} README}

\begin{document}

\maketitle

\bigskip 


\section{System requirements:}

We use three pieces of software:

\begin{itemize}
\item Python 3.7.6 via Jupyter Notebook: scraping of government social media accounts and newspapers to generate part of the policy database. 
\item R  4.0.2 via RStudio 1.3.1073 (all packages used on R as specified in the code): production of figures.
\item Stata/MP 16.0 and Stata/MP 17.0 (Stata packages pdslasso (v1.1), lassopack (v1.3.1), and reghdfe (5.8.0)): statistical analysis.
\end{itemize}

\section{Installation guide:}

To open Jupyter Notebook:
\begin{itemize}
\item Open Terminal
\item type \texttt{cd [NEW WORKING DIRECTORY]}, for example, \texttt{cd Desktop}
\item type \texttt{jupyter notebook}---a new window of default browser will pop up
\end{itemize}

\noindent To open/install R Studio:
\begin{itemize}
\item Download and follow instructions for RStudio Desktop in this \href{https://www.rstudio.com/products/rstudio/}{\textcolor{blue}{link}}. This is an open source software.
\end{itemize}

\noindent To open/install Stata/MP 17.0:
\begin{itemize}
\item Download and follow instructions for Stata/MP 17.0 in this \href{https://www.stata.com/statamp/}{\textcolor{blue}{link}}. This is not a free software.
\item Once installed, start a new session in Stata.
\item Install the following packages \texttt{pdslasso}, \texttt{lassopack}, and \texttt{reghdfe} by typing: \texttt{ssc intall [NAME OF THE PACKAGE]} followed by \texttt{ENTER}.
\end{itemize}

\section{Instructions for use:}

\section*{Running the statistical analysis}

\large{To conduct the statistical analyses, run \textit{DoFile\_master.do} in Folder ``Analysis'' to run analyses (highlight code and type \texttt{Command + Shift + D} or \texttt{Ctrl + Shift + D}). Output is the final database (\texttt{panel\_COVIDTreatMR}) and five csv files containing the estimates of all models:  \texttt{m1.csv}, \texttt{m2.csv}, \texttt{m3.csv}, \texttt{m4.csv}, and \texttt{m5.csv}. First three models take about 3 minutes to run each; fourth model takes about 10 minutes; and fifth model takes about 3 hours. Further below in this README file we describe how to produce the figures.}

\section*{Further details on the structure of the statistical analysis:}
There is no need to run the following components separately; they are all run by the master do file (\textit{DoFile\_master.do}), as explained above.

\subsection*{Construction of databases}
Folder ``Dataset''.
\subsubsection*{COVID}
Run \textit{DoFile\_CleanPanelCOVID.do} on Stata. The code produces a clean database at the municipality-day level, \texttt{panel\_COVID\_fixdates}, based on \texttt{08232020COVID19MEXICO.csv}, which is a database directly downloaded from the Mexican Ministry of Health \href{https://www.gob.mx/salud/documentos/datos-abiertos-bases-historicas-direccion-general-de-epidemiologia}{\textcolor{blue}{website}} on August 2020 (the present analysis is restricted to the first semester of 2020).

\subsubsection*{Lockdowns}
Run \textit{DoFile\_CleanLockdowns.do} on Stata. This code cleans and harmonizes multiple datasets of social distancing policies at the municipal-day level. The database produced is \texttt{panel\_COVID\_Lockdowns}. In particular, it appends data from newspapers, Twitter, Facebook, as well as local governments' websites and social media accounts. 

The first part of this database is generated by running all files with the extension ipynb: \texttt{0-scrape}, \texttt{search\_accounts}, \texttt{local-accounts}, \texttt{local-gob\_mapping}, \texttt{tweets\_gobiernos-locales}, \texttt{tweets\_gobiernos\_estatales}, \\ \texttt{facebook-local\_gob}, and  \texttt{policy\_actions} in that order on Jupyter Notebook. The output is curated by hand in the file \texttt{policy\_action.csv}.

The second part of the database is coded by hand searching terms online using a dictionary. These data is contained in \texttt{Entidad.xlsx}.

\subsubsection*{Facebook Mobility data}

Run \textit{DoFile\_CleanFBMovementRange.do} on Stata. This code both cleans and consolidates a database of Facebook mobility data at the municipal-day level and also merges the previous two databases (\texttt{panel\_COVID\_fixdates} and \texttt{panel\_COVID\_Lockdowns}). The output is a municipal-day level database, \texttt{panel\_COVIDTreatMR}, that contains epidemiological data, social distancing policies data, and Facebook mobility data including mobility weights.

\subsection*{Analysis}
Folder ``Analysis''.
\subsubsection*{Main analysis}

Main analysis is performed by running \textit{DoFile\_analysis.do} on Stata. The code yields, with the help of \textit{DoFile\_append\_m*}, five .csv files: \texttt{m1.csv}, \texttt{m2.csv}, \texttt{m3.csv}, \texttt{m4.csv}, and \texttt{m5.csv} named after the model number. Each row in such files contains a point estimate, 95\% confidence intervals, number of observations, as well as the indicator of the model. 

\subsubsection*{Regression estimates}

Regression table in Supplementary materials (Table S1) is produced by running \textit{DoFile\_regressiontable.do}, which estimates four models and calculates differences between point estimates. The code produces \texttt{pvalues\_models1-4.csv}.

\section*{Creation of figures:}

%\subsection*{Figures}

Folder ``Figures''.

\subsubsection*{Main (Figures 2, 3, 4, S5, S6, S7)}

Based on the five .csv files produced in the main analysis (\texttt{m1.csv}, \texttt{m2.csv}, \texttt{m3.csv}, \texttt{m4.csv}, and \texttt{m5.csv}), \textit{Rscript\_graphs\_threepanels.R} produces the figueres included in the main text (Figures 2 and 4) and the Supplementary materials (Figures S5, S6, and S7). Finally, \textit{Rscript\_heatmap\_noquadratic\_signs.R} produces the heatmaps that show relevant pairwise policy interactions (Figure 3) based on results from model 5 from the main analysis, which are formatted using
\textit{DoFile\_csv\_nodiagonal.do}.

\subsubsection*{Population (Figures 1 and S1)}

Based on \texttt{panel\_COVID\_Lockdowns} and Mexican census data (\texttt{population\_2020}), we produce Figure 1 that shows the total population and the share of the total population subject to each of the social distancing policies in sample. \textit{population\_date\_graph.R} produces Figure 1 (to run code highlight lines of code and click \texttt{Command + Enter} or \texttt{Ctrl + Enter}). Likewise, and using data directly downloaded from the \href{https://www.coronanet-project.org/}{\textcolor{blue}{CoronaNet project}} (Database Version 1.0 (core)), we wrangle the data to have the same format as Figure 1 using \textit{DoFile\_Coronanet.do}. Figure S1, which shows the proportion of the world population subject to specific social distancing policies is produced by \textit{policies\_nature\_graph.R}.

\subsubsection*{Histogram (Figures S2 and S3)}

Figures S2 and S3 in Supplementary materials show the distribution of local and inflow weights. These figures are produced running \textit{histograms.R} based on \texttt{weights\_dow} that includes weights at the municipality-day level.

\subsubsection*{Maps (Figure S4)}

Finally, we include maps showing the distribution of our sample---municipalities for which we have post-pandemic Facebook mobility data and for those that we are able to calculate weighted policies based on pre-pandemic Facebook mobility data. We produce such maps using \textit{RScript\_maps.R} based on our sample shown in \texttt{maps\_sample.csv} and Mexican municipalities shapefiles (in folder ``muni\_2018gw'').

\end{document}